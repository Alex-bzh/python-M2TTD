{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0818d992-55cf-47f4-8d01-918492b30d27",
   "metadata": {},
   "source": [
    "# La régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80672ed-3716-4501-99d9-540cf8f2789b",
   "metadata": {},
   "source": [
    "Mettons que vous disposez des mesures annuelles de précipitations en millimètres sur la commune de Pont-Aven dans le Finistère depuis les années 2000 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5f0ee-c178-4c66-9041-c1ebac3a90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = [974.5, 879.3, 997.2, 1128.5, 864.9, 864.9, 1136.9, 1015.1, 829.6, 981.4, 830.5, 830.1, 936.3, 613.0, 641.3, 815.7, 748.1, 947.1, 763.8, 688.2, 1119.8, 866.1, 910.1, 686.3, 876.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71c0e36-fde7-46f4-a12b-5cd4cab8910f",
   "metadata": {},
   "source": [
    "En calculant la moyenne, vous obtenez une évaluation des précipitations sur un an :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5252c-3d3a-445d-ad10-119562e27efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = sum(rainfall) / len(rainfall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77523a6b-53e1-4d71-b925-296d9d5b5e79",
   "metadata": {},
   "source": [
    "Vous pourriez en conclure que, dans un contexte idéal sans variation notable ni accélération de la dérive climatique, `mean` est un estimateur correct des précipitations pour l’année suivante mais avec une certaine marge d’erreur. Quelle est cette erreur ?\n",
    "\n",
    "La manière la plus intuitive de la déterminer est de prendre l’écart de chaque valeur avec `mean` puis d’en faire une moyenne. Et comme deux écarts positif et négatif se compensent tant et si bien que l’on pourrait faussement conclure que `mean` prédit sans erreur les précipitations pour l’année suivante et toutes celles après elle, il est de bon ton soit de considérer les valeurs absolues soit de les élever au carré. Avec cette deuxième option, nous calculons la variance empirique du système :\n",
    "\n",
    "$$\n",
    "s^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e273dd-29c8-4200-9cd7-b8e27de5e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = sum((x - mean) ** 2 for x in rainfall) / len(rainfall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d72121-6fad-4f8d-bee7-c7b3f9770031",
   "metadata": {},
   "source": [
    "Pour tenir compte du biais de l’échantillonnage, on a plutôt coutume de calculer la variance empirique corrigée (ou non biaisée) :\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d1bb5f-a4e2-4567-8a46-35877166b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = sum((x - mean) ** 2 for x in rainfall) / (len(rainfall) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b08bf9-62e9-42c5-a978-7b4d06c36eaf",
   "metadata": {},
   "source": [
    "Cette mesure s’exprimant dans une unité qui ne fait pas immédiatement sens, à savoir les $mm^2$, on les rapporte à une échelle compréhensible en prenant la racine carrée, de manière à obtenir l’écart-type non biaisé :\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d3d0f-ce25-444e-ac9d-7ad9f6b8efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation = variance ** .5\n",
    "\n",
    "print(f\"Les précipitations moyennes au-dessus de la commune de Pont-Aven avoisinent les {round(mean)} mm avec un écart-type de {round(deviation)} mm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244507d6-5a15-4b53-a50d-739921c3da90",
   "metadata": {},
   "source": [
    "Le modèle que nous venons de construire repose essentiellement sur une mesure de tendance centrale calculée à partir d’une seule variable, la pluviométrie. Si nous lui rajoutions une seconde variable, par exemple la température annuelle moyenne, nous disposerions alors de deux coordonnées qu’il serait intéressant d’analyser soit visuellement en les projetant dans un plan en deux dimensions soit en mesurant leurs interactions.\n",
    "\n",
    "L‘une des façons de faire serait par exemple de calculer une fonction affine, autrement appelée droite de régression linéaire, qui s’exprime sous la forme :\n",
    "\n",
    "$$\n",
    "y = mx + b\n",
    "$$\n",
    "\n",
    "Pour la petite histoire, c’est en 1886 que le terme de régression apparaît pour la première fois, dans un article de Sir Francis Galton qu’il publie sous le titre de *Regression Towards Mediocrity in Hereditary Stature*. Dans cet article, il mettait en évidence que les enfants de personnes de grandes tailles avaient tendance à être plus petits qu’elles, et inversement, d’où l’idée d’une régression vers la médiocrité pour décrire un phénomène d’attraction vers la moyenne.\n",
    "\n",
    "Avant de monter notre modèle, chargeons toutes les bibliothèques nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a0837-2957-47b6-b537-0333f7e95c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, shapiro, levene, bartlett"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50fd306-bf58-4420-9dec-7c7dcc9d640d",
   "metadata": {},
   "source": [
    "## Rappels sur l’équation réduite d’une droite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9cf6e3-afca-48a6-9bf5-1868ae89d81b",
   "metadata": {},
   "source": [
    "Dans un plan orthonormé, une droite passe au minimum par deux points de coordonnées $(x1;y1)$ et $(x2;y2)$. Elle est caractérisée par une pente, son coefficient directeur, et par son ordonnée à l’origine, c’est-à-dire l’ordonnée de son point d’intersection avec l’axe des ordonnées. Dans la formule $y = mx + b$, le terme $m$ est le coefficient directeur et $b$ l’ordonnée à l’origine.\n",
    "\n",
    "Commençons par matérialiser une droite quelconque dans un plan en considérant les points de coordonnées $(2;3)$ et $(4;9)$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875505e8-03a9-4f4b-b96d-6bb795c17b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2, 4]\n",
    "y = [3, 9]\n",
    "\n",
    "plt.xlim([0, 10])\n",
    "plt.ylim([0, 10])\n",
    "plt.grid(True)\n",
    "sns.regplot(x=x, y=y, ci=None)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fc2318-2249-43ec-aeac-0a771068370e",
   "metadata": {},
   "source": [
    "### Le coefficient directeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ecb37e-07d3-4e93-9e14-4527c1153b09",
   "metadata": {},
   "source": [
    "Le coefficient directeur détermine la pente de la droite : s’il est positif, la droite monte ; s’il est négatif, la droite descend. Pour le calculer, la formule est :\n",
    "\n",
    "$$m = \\frac{\\Delta y}{\\Delta x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c080d51-adf5-48ba-8807-c83d6f751898",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (y[0] - y[1]) / (x[0] - x[1])\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c006f-5dee-4707-b238-69174a38e5d7",
   "metadata": {},
   "source": [
    "### L’ordonnée à l’origine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532a3a7-b6b5-4a02-95f9-10dfe3a89c93",
   "metadata": {},
   "source": [
    "Maintenant que nous connaissons *m*, il reste à calculer *b*, qui est l’ordonnée à l’origine. Or, nous savons que l’un des points de cette droite a pour coordonnées $(2;3)$, qui en est une solution. C’est-à-dire que lorsque *x* vaut 2, alors *y* vaut 3. Le droite qui nous occupe a donc pour équation :\n",
    "\n",
    "$$y = 3x + b$$\n",
    "\n",
    "D’où :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "3 &= 3 \\times 2 + b \\\\\n",
    "b &= -3 \\times 2 + 3 \\\\\n",
    "b &= -3\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1dfb5-b374-44db-bc28-9d73b0218e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = -3 * 2 + 3\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e281231-eacd-4f44-b4ec-0466a6eafd79",
   "metadata": {},
   "source": [
    "Nous pouvons afficher cet autre point de coordonnées $(0;-3)$ sur la droite afin de vérifier graphiquement si la solution est correcte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80677c8-7377-49f0-bdc9-79c8d47a7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2, 4, 0]\n",
    "y = [3, 9, -3]\n",
    "\n",
    "plt.xlim([-1, 10])\n",
    "plt.ylim([-4, 10])\n",
    "plt.grid(True)\n",
    "sns.regplot(x=x, y=y, ci=None)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c7aec-b29e-4624-8db8-cb1c708e38cd",
   "metadata": {},
   "source": [
    "Nous pouvons ainsi conclure que l’équation réduite de la droite est : $$y = 3x -3$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963a81e-3a21-44f0-9e60-cc90d026e6d5",
   "metadata": {},
   "source": [
    "## Une droite de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c288211-a1de-47b2-81e9-df092e538a43",
   "metadata": {},
   "source": [
    "L’exemple introductif montrait comment calculer l’équation réduite d’une droite dont on connaît deux points. Le problème dans le cas de la régression, c’est que justement nous ne les connaissons pas ces points.\n",
    "\n",
    "Avant d’établir un modèle linéaire, il est judicieux d’examiner la relation entre deux variables afin de déterminer si elles se prêtent bien à l’exercice. On peut le faire soit visuellement soit à l’aide d’un coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1155b11a-587e-4ec7-94ce-1782d948183f",
   "metadata": {},
   "source": [
    "### Vérifier graphiquement si deux variables sont corrélées de manière linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b96ca-5efc-4161-b619-e02a10ed5e51",
   "metadata": {},
   "source": [
    "Matérialisons concrètement la question avec un jeu de données sur des manchots en Antarctique ([Gorman, 2014](0.about-datasets.ipynb#Size-measurements-for-adult-foraging-penguins-near-Palmer-Station,-Antarctica)) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc441d-29e7-4082-8d62-1c114221a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/penguin-census.csv\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,5))\n",
    "sns.scatterplot(data=df, x=\"body_mass_g\", y=\"flipper_length_mm\", ax=ax1)\n",
    "sns.regplot(data=df, x=\"body_mass_g\", y=\"flipper_length_mm\", ci=None, ax=ax2)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d082d-092e-4f49-80fe-e2e2a675ed1c",
   "metadata": {},
   "source": [
    "Nous venons d’afficher deux nuages de points qui représentent deux caractéristiques des manchots : la masse en grammes sur l’axe des abscisses et la longueur des nageoires en millimètres sur l’axe des ordonnées. Nous notons clairement une tendance : lorsque la masse d’un manchot augmente, la longueur de ses nageoires aussi. Ceci dit, la relation entre les deux caractéristiques n’est pas strictement linéaire : aucun individu n’est identique et nous ne pouvons être sûr·es que, si un manchot pèse *x* grammes de plus qu’un autre, ses nageoires mesureront *y* mm de plus.\n",
    "\n",
    "Sur le graphique de droite, nous avons en plus affiché la droite de régression. Cette droite nous montre la tendance centrale qui minimise la somme des erreurs pour toutes les observations et qui nous permettrait en plus de prédire pour une certaine masse la longueur des nageoires d’un manchot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95cb25-5527-4557-8640-bf7d12bcf50d",
   "metadata": {},
   "source": [
    "### Déterminer la corrélation à l’aide d’un coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f09e6a-cc3d-4b6d-aeec-be183ef06423",
   "metadata": {},
   "source": [
    "Les coefficients de corrélation et de détermination de Pearson sont deux manières d’analyser la relation entre deux variables. La bibliothèque *Scipy* met à disposition une fonction `pearsonr()` pour les obtenir directement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a55375-4d95-4cb5-b0bc-d6166a2efeed",
   "metadata": {},
   "source": [
    "#### Le coefficient de corrélation de Pearson (*r*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e4aea-845b-4f8b-890d-7ef942cb6a16",
   "metadata": {},
   "source": [
    "Il mesure la force et la direction de la relation linéaire entre deux variables dans un intervalle $[-1,1]$ où un *r* proche de 1 ou -1 indique une forte corrélation linéaire, tandis qu’un *r* proche de 0 indique une absence de relation linéaire. Il s’exprime mathématiquement par la formule :\n",
    "\n",
    "$$\n",
    "r = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2 \\cdot \\sum_{i=1}^n (y_i - \\bar{y})^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47330648-0bf8-41f4-9c2c-f4fa182f3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, _ = pearsonr(df.dropna().body_mass_g.values, df.dropna().flipper_length_mm.values)\n",
    "\n",
    "print(f\"r de Pearson : {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4a45e-0794-4073-848d-1ba4707cd1aa",
   "metadata": {},
   "source": [
    "#### Le coefficient de détermination linéaire de Pearson ($R^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b0808-6d40-40ae-80ce-1ba8e14f445e",
   "metadata": {},
   "source": [
    "Le $R^2$ est la somme des carrés des résidus et de la variance totale :\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^k(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^k(y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "Il mesure la qualité de la prédiction d’un modèle de régression linéaire en évaluant la variance d’une variable en fonction d’une autre dans l’intervalle $[0,1]$ où un $R^2$ de 1 est un score parfait quand un score de 0 indiquerait que le modèle prédit toujours la valeur attendue (la moyenne). Un score négatif reste possible mais serait révélateur d’une erreur de méthodologie (données arbitrairement mauvaises)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833724ab-c983-41a5-aa5b-c2a4ec252402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R^2 de Pearson : {r ** 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a484fa-a56f-4a8d-8664-287caa9d33d1",
   "metadata": {},
   "source": [
    "## La droite de régression des moindres carrés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c393566-1ec5-43c0-8507-a45d6d127002",
   "metadata": {},
   "source": [
    "Lorsque nous prenons les coordonnées d’une observation, nous remarquons bien qu’elles sont éloignées de la droite. Il existe un décalage, que l’on appelle communément une erreur, et la droite de régression des moindres carrés est celle qui minimise la somme des carrés de toutes les erreurs, le rapport s’établissant au carré afin d’éviter les valeurs négatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a569e4-7b0e-45e5-abfc-98b8354cb827",
   "metadata": {},
   "source": [
    "### La formule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36359ada-5043-454b-8a73-7e2259188d22",
   "metadata": {},
   "source": [
    "L’équation réduite qui permet d’obtenir les coordonnées de tous les points de la droite et, partant, d’obtenir une prédiction de $\\hat{y}$ en fonction de $x$, respecte la forme $\\hat{y} = mx + b$. Deux étapes majeures pour la trouver, calculer d’abord le coefficient directeur $m$ puis l’ordonnée à l’origine $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d8477-8155-49a6-bd31-19477118ea73",
   "metadata": {},
   "source": [
    "### Calculer le coefficient directeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f589553-4423-4cd1-9a9a-2dbdfc59616a",
   "metadata": {},
   "source": [
    "La résolution du coefficient directeur d’une droite des moindres carrés est régi par la formule ci-dessous, où $n$ est le nombre des observations :\n",
    "\n",
    "$$m = \\frac{n\\sum xy - \\sum x \\sum y}{n \\sum x^2 - \\left(\\sum x\\right)^2}$$\n",
    "\n",
    "Commençons par définir un nouveau *data frame* avec l’ensemble des valeurs pour les caractéristiques *body_mass_g* et *flipper_length_mm* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434f2fd-1810-4ac3-a64b-f941848e43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for educational purposes, NA have been removed\n",
    "data = df.loc[:,[\"body_mass_g\",\"flipper_length_mm\"]].dropna()\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e7330-0f3a-4912-b7af-da7dfa2b5afa",
   "metadata": {},
   "source": [
    "Récupérons individuellement les coordonnées *x* et *y* qui représentent respectivement la variable prédictive et la variable cible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2c50d-a77c-4d2b-bd01-9aeb7eaef317",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data.body_mass_g.values, data.flipper_length_mm.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408bbc73-1aa1-47eb-b309-f9312cb540c9",
   "metadata": {},
   "source": [
    "Il ne nous reste plus qu’à créer une fonction `slope()` qui implémente la formule plus haut afin de calculer le coefficient directeur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377309ab-61ae-440b-8db6-2e872b48fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(x, y):\n",
    "  \"\"\"Return the slope of a straight line,\n",
    "  with the least squares method.\n",
    "\n",
    "  Arguments:\n",
    "  x -- data in x-axis\n",
    "  y -- data in y-axis\n",
    "  \"\"\"\n",
    "\n",
    "  n = len(x)\n",
    "  sum_xy = sum(x * y)\n",
    "  sum_x_squared = sum(x) ** 2\n",
    "  sum_x = sum(x)\n",
    "  sum_y = sum(y)\n",
    "  sum_squares_x = sum(x ** 2)\n",
    "\n",
    "  # formula\n",
    "  m = (n * sum_xy - sum_x * sum_y) / (n * sum_squares_x - sum_x_squared)\n",
    "\n",
    "  return m\n",
    "\n",
    "m = slope(X, Y)\n",
    "\n",
    "print(f\"Le coefficient directeur de la droite des moindres carrés est approximativement de {m:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2d022-880c-4363-a42c-6862ff29d6e3",
   "metadata": {},
   "source": [
    "### Calculer l’ordonnée à l’origine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c20a34-3e61-40a3-9e61-8bcf9b8feb8f",
   "metadata": {},
   "source": [
    "La formule de résolution de l’ordonnée à l’origine fait appel au coefficient directeur et aux moyennes des valeurs de $x$ et de $y$ :\n",
    "\n",
    "$$b = \\bar{y} - m\\bar{x}$$\n",
    "\n",
    "Nous pouvons traduire cette formule dans une fonction `intercept()` et la calculer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3898bca-d5d9-4dcf-a269-7bac9ff1e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercept(m, x, y):\n",
    "    \"\"\"Intercept of a straight line.\n",
    "    \n",
    "    Arguments:\n",
    "    m -- weight\n",
    "    x -- data in x-axis\n",
    "    y -- data in y-axis\n",
    "    \"\"\"\n",
    "\n",
    "    avg_x = np.average(x)\n",
    "    avg_y = np.average(y)\n",
    "    \n",
    "    return avg_y - (m * avg_x)\n",
    "\n",
    "b = intercept(m, X, Y)\n",
    "\n",
    "print(f\"L’ordonnée à l’origine de la droite des moindres carrés est approximativement de {b:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c3430-7b22-4ba7-b808-7144c43e88d1",
   "metadata": {},
   "source": [
    "De là, nous pouvons conclure que la fonction affine qui modélise la relation linéaire entre la masse en grammes (*x*) et la longueur des nageoires des manchots (*y*) est de :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354ed12-e24e-4e8c-8de5-96315c1e1c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ŷ = {m}x + {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66728a-617b-4ad8-b073-065ad4ca87f3",
   "metadata": {},
   "source": [
    "### Tracer la droite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f785c-3229-44c0-85f7-03be157ca814",
   "metadata": {},
   "source": [
    "Grâce à la fonction affine obtenue précédemment, il est à présent simple d’obtenir des prédictions en fonction d’une coordonnée ou de l’autre. Définissions une fonction `predict()` pour prédire la longueur des nageoires d’un manchot à partir du moment où l’on connaît son poids :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40a633-a9d2-4800-b1ff-a664d9d66470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, m, b):\n",
    "    \"\"\"Solution to the standard form equation\n",
    "    of a straight line.\n",
    "\n",
    "    Keyword-only arguments:\n",
    "    x -- value of x\n",
    "    m -- slope\n",
    "    b -- intercept\n",
    "    \"\"\"\n",
    "    return m * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c698be4-b774-4042-b8f5-f273a620ff27",
   "metadata": {},
   "source": [
    "La question est désormais de savoir, pour tous les manchots de notre jeu de données, quelle devrait être la longueur de leurs nageoires en situation idéale. Nous pouvons le déterminer grâce à notre fonction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20915c-dcc0-4122-8c2f-fd71cbd2c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = [ predict(x, m, b) for x in X ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1e9dd-3dc7-4ce6-9a9f-79a6078cbf80",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant comparer si notre modèle linéaire est similaire à celui proposé plus haut par *Seaborn* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250600d5-ae25-4de4-865e-a05d9782119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# predictions with our linear model\n",
    "sns.lineplot(x=X, y=Y_pred, color=\"fuchsia\", ax=axes[0], label=\"Linear model\")\n",
    "sns.scatterplot(x=X, y=Y, color=\"seagreen\", ax=axes[0], label=\"Observations\")\n",
    "axes[0].set(xlabel=\"Body mass (g)\", ylabel=\"Flipper length (mm)\")\n",
    "axes[0].legend()\n",
    "sns.despine(ax=axes[0])\n",
    "\n",
    "# linear regression with regplot\n",
    "sns.regplot(data=df, x=\"body_mass_g\", y=\"flipper_length_mm\", ci=None, ax=axes[1])\n",
    "axes[1].set(xlabel=\"Body mass (g)\", ylabel=\"Flipper length (mm)\")\n",
    "sns.despine(ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bebc5ed-f883-4dc4-a84b-c9c6369eaa77",
   "metadata": {},
   "source": [
    "## Établir une mesure de la performance du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f75f9f-5076-48de-8f19-4c43137e06c6",
   "metadata": {},
   "source": [
    "Si la droite obtenue par un calcul manuel correspond au graphique attendu, il reste encore à évaluer la performance du modèle. Nous abordons trois métriques possibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97db1b-df80-468e-83e0-ac3572703854",
   "metadata": {},
   "source": [
    "### L’erreur quadratique moyenne (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bdff4a-db1e-460c-b0fb-4c0bc6d13715",
   "metadata": {},
   "source": [
    "La MSE (*mean square error*) et sa cousine, la RMSE (*root mean square error*), sont les deux métriques les plus couramment utilisées en *machine learning*. La MSE calcule la moyenne des carrés des erreurs selon la formule :\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{k}\\sum_{i=0}^{k-1}(y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Comme entre en jeu un calcul au carré, la MSE pénalise plus fortement les grandes erreurs et, dans le même ordre d’idée, sera très sensible aux données aberrantes (*outliers*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b972f1-6c16-428e-9ffc-7bf56827c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(data, predictions):\n",
    "\n",
    "    # formula\n",
    "    mse = sum((y - y_pred) ** 2 for y, y_pred in zip(data, predictions)) / len(data)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "print(f\"MSE : {mean_squared_error(Y, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda0869-89fe-4d5e-952e-063374190f6c",
   "metadata": {},
   "source": [
    "### La racine de l’erreur quadratique moyenne (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832cf798-9a1f-4374-b685-43ae03e67835",
   "metadata": {},
   "source": [
    "Plus facile à interpréter que la MSE, la RMSE (*root mean square error*) s’exprime dans l’unité de la variable à prédire en extrayant la racine carrée de la MSE :\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{ \\frac{1}{k}\\sum_{i=0}^{k-1}(y_i - \\hat{y}_i)^2 }\n",
    "$$\n",
    "\n",
    "À noter qu’elle souffre des mêmes limites que la MSE : une grande sensibilité aux *outliers* ainsi qu’une incidence forte sur les erreurs importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea60ca-4317-4c54-aeef-496895cb35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(data, predictions):\n",
    "\n",
    "    # formula\n",
    "    mse = sum((y - y_pred) ** 2 for y, y_pred in zip(data, predictions)) / len(data)\n",
    "    \n",
    "    return mse ** .5\n",
    "\n",
    "print(f\"RMSE : {root_mean_squared_error(Y, Y_pred)} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff25569-9d9b-43c5-a388-ac280d0edb2d",
   "metadata": {},
   "source": [
    "### L’erreur absolue moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6628f88-1cfc-4973-8bdb-dff399487388",
   "metadata": {},
   "source": [
    "Quand les valeurs extrêmes d’un jeu de données sont quantitativement importantes, la RMSE pourrait conduire à des erreurs d’interprétation. Dans un tel cas de figure, la MAE (*mean absolute error*) peut lui être préférée : en calculant la moyenne de valeurs absolues, elle ne pénalise plus autant les grandes erreurs et se rend moins sensible aux données aberrantes. La formule de la MAE vaut ainsi :\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{k}\\sum_{i=0}^{k-1} \\lvert y_i - \\hat{y}_i\\rvert\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ada22-e247-496b-8588-e14bb824c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(data, predictions):\n",
    "\n",
    "    mae = sum(abs(d - p) for d, p in zip(data, predictions)) / len(data)\n",
    "    return mae\n",
    "\n",
    "print(f\"MAE : {mean_absolute_error(Y, Y_pred)} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b776558-5305-44c7-89cf-bf3c642783dc",
   "metadata": {},
   "source": [
    "## Analyse des résidus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e554cc-617e-4614-8643-16ed8540c250",
   "metadata": {},
   "source": [
    "Nous avons établi plus haut la fonction affine qui permet de tracer la droite de régression qui minimise la moyenne des écarts à la moyenne :\n",
    "\n",
    "$$\n",
    "y = mx + b\n",
    "$$\n",
    "\n",
    "Nous avons également relevé qu’il existait, entre cette droite idéale tracée par les prédictions et les valeurs observées empiriquement, un écart que nous avons nommé *erreur*. Dans le modèle de régression linéaire, nous ajoutons ce paramètre à la fonction affine en terme de *bruit* :\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\epsilon\n",
    "$$\n",
    "\n",
    "La notion de bruit traduit la variabilité entre les prédictions du modèle et les observations réelles et nous permet d’identifier ses lacunes en vérifiant notamment si les hypothèses fondamentales, comme l’homoscédasticité et la linéarité, sont bien respectées. On effectue pour cela une **analyse des résidus**.\n",
    "\n",
    "Les résidus, ce sont ces écarts entre les prédictions et la variable indépendante qui constituent la partie inexpliquée de notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5feb1-7e06-48ae-951a-dbdb95403b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = Y - Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e376893-1dc1-4ac0-bca3-97d47ebfc6bd",
   "metadata": {},
   "source": [
    "Plus que de simples erreurs sans signification, leur distribution peut nous renseigner sur la précision du modèle : si elle est aléatoire et de faible amplitude, elle révèlera que le modèle capture bien les structures sous-jacentes des données ; à l’inverse, des résidus structurés ou de grande amplitude suggèreront que le modèle est inadéquat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e62eb-fb38-4f67-aeec-04f0fcf3ab66",
   "metadata": {},
   "source": [
    "### Visualisation des résidus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10d794-7cba-44cb-95cf-19762ae45792",
   "metadata": {},
   "source": [
    "En affichant le **terrain résiduel**, nous devons être en mesure de confirmer les hypothèses fondamentales de tout modèle linéaire, à savoir **la linéarité** et **l’homoscédasticité** (la variance des résidus est constante). Si les points sont répartis aléatoirement autour de la ligne de référence qui matérialise l’absence de résidus, tout va bien ! Si au contraire on remarque des regroupements ou si un motif apparaît, comme une courbe, alors notre modèle n’est pas adapté.\n",
    "\n",
    "Dans notre exemple, le phénomène aléatoire nous semble bien retranscrit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eecd4dc-78b4-4819-ac0d-b0072a96d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=Y_pred, y=residuals, marker='^', alpha=0.7, s=80, linewidth=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residual plot', fontsize=14)\n",
    "plt.xlabel('Predicted values', fontsize=12)\n",
    "plt.ylabel('Residuals', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c69925-87e1-4d3e-a7c0-847cb1bbf659",
   "metadata": {},
   "source": [
    "### Tester la normalité d’une distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2746b3-501a-4397-9635-964b16a4d88a",
   "metadata": {},
   "source": [
    "Afin de prouver que la distribution des résidus est un phénomène aléatoire, on peut la soumettre à un test statistique comme celui de Shapiro-Wilk qui vérifie sa normalité. L’hypothèse nulle $H_0$ établit que les résidus sont normalement distribués.\n",
    "\n",
    "Avec une valeur-p inférieure au seuil de 0,05, nous la rejetons et devons conclure que notre modèle n’est pas adéquat à décrire les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3ef0e-b392-44de-871e-5b206ec75215",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = shapiro(residuals)\n",
    "print(\n",
    "    f\"Score : {stat}\",\n",
    "    f\"Valeur-p : {p_value}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59560112-f0b5-4b89-8b15-9e7a797e8c05",
   "metadata": {},
   "source": [
    "D’autres tests existent, comme celui de Kolmogorov-Smirnov (plus sensible aux écarts dans de grands ensembles d’échantillons) ou encore celui de Anderson-Darling qui va définir des seuils critiques sans calculer une valeur-p directement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10263e0-49f2-4f18-9336-5b95cab3902d",
   "metadata": {},
   "source": [
    "### Tester l’homoscédasticité d’une distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb0bf10-dc31-441c-a63f-a5434afcc9a8",
   "metadata": {},
   "source": [
    "Afin de déterminer si la variance est constante dans les résidus, nous pouvons constituer deux groupes séparés par la médiane :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b21b1-4d0d-4a9a-b033-953f048e42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = residuals[Y_pred < np.median(Y_pred)]\n",
    "group2 = residuals[Y_pred >= np.median(Y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a8ce1-4040-415a-b533-3f512ae926c8",
   "metadata": {},
   "source": [
    "Et lancer le test de Bartlett qui évalue si leurs variances sont égales :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216223b6-af26-408a-acf1-05724be73c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = bartlett(group1, group2)\n",
    "\n",
    "print(\n",
    "    f\"Score : {stat}\",\n",
    "    f\"Valeur-p : {p_value}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8a9cc-e541-45d8-a031-d5daa6d86d07",
   "metadata": {},
   "source": [
    "Avec une valeur-p supérieure au seuil de 0,05, nous pouvons conserver l’hypothèse nulle d’homoscédasticité.\n",
    "\n",
    "Malgré tout, gardons à l’esprit que nos résidus ne sont pas normalement distribués et optons pour un test moins sensible à la contrainte de normalité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4493853-e7f7-4e79-8af5-ff715e7188c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = levene(group1, group2)\n",
    "\n",
    "print(\n",
    "    f\"Score : {stat}\",\n",
    "    f\"Valeur-p : {p_value}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d55229-3b66-4be9-8063-2f604fe2b2f9",
   "metadata": {},
   "source": [
    "La valeur-p est toujours supérieure au seuil 0,05, ce qui tend à valider l’hypothèse nulle de constance de la variance entre les différents groupes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
