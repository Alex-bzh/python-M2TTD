{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9963a116-f067-4597-b69e-997a00adb26e",
   "metadata": {},
   "source": [
    "# Le partitionnement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d64df-3a47-4165-97b2-bd817b7b82b8",
   "metadata": {},
   "source": [
    "Le partitionnement (*clustering*) est une technique courante des statistiques multivariées pour effectuer des tâches de regroupement entre variables afin de révéler une structure sous-jacente. Il s’agit d’une méthode exploratoire qui aide à la classification des données en regroupant les individus dans des ensembles cohérents où la variance intra-groupes est minimisée quand la variance inter-groupes est, elle, maximisée.\n",
    "\n",
    "Importons les modules qui seront nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec46f4e-5f5a-4ba9-8d47-c36c90cab5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd71b3cd-e546-4549-a4b5-68565e8042d0",
   "metadata": {},
   "source": [
    "## Une matrice de dissimilarité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c0949-3a61-46b7-b0ca-67adc6d3e081",
   "metadata": {},
   "source": [
    "### Avec des variables catégorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c9f95-bc15-4c22-b667-6c2119e3efd4",
   "metadata": {},
   "source": [
    "Prenons les réponses de cinq étudiant·es à un test comportant dix questions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333da78-df81-4bba-971d-a624fcb0794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_students = 5\n",
    "n_questions = 10\n",
    "\n",
    "data = [\n",
    "    [\n",
    "        random.choice(['A', 'B', 'C', 'D'])\n",
    "        for _ in range(n_questions)\n",
    "    ]\n",
    "    for _ in range(n_students)\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, index=[f\"Student {i+1}\" for i in range(n_students)], columns=[f'Q{i+1}' for i in range(0, n_questions)])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db398a-4716-4632-ac57-7e8ad2291116",
   "metadata": {},
   "source": [
    "Et faisons la comparaison deux à deux pour comptabiliser le nombre de fois où leurs réponses divergent. Enfin, normalisons en divisant le résultat par le nombre de questions afin d’obtenir un score entre 0 et 1 où 0 correspond à des étudiant·es aux réponses similaires et 1 des étudiant·es qui n’auront jamais répondu pareil :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1cace7-bedd-44dd-bee6-fdda64c750b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = df.values\n",
    "\n",
    "# calculate differences between rows\n",
    "row_diffs = (data_array[:, None] != data_array).sum(axis=2)\n",
    "\n",
    "# normalize\n",
    "dissimilarity_matrix = row_diffs / n_questions\n",
    "\n",
    "# matrix to a DataFrame\n",
    "dissimilarity_df = pd.DataFrame(dissimilarity_matrix, index=df.index, columns=df.index)\n",
    "\n",
    "display(dissimilarity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d181c10-5acd-4cdf-9898-f2490510d347",
   "metadata": {},
   "source": [
    "Il est à présent facile d’identifier les paires d’étudiant·es dont les réponses se ressemblent le plus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb731e8-69fd-4074-8ba9-d701646ea996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum score > 0 to exclude pairs consisting of the same student\n",
    "min_score = dissimilarity_df[dissimilarity_df > 0].min().min()\n",
    "\n",
    "# all the pairs concerned\n",
    "clusters = dissimilarity_df[dissimilarity_df == min_score].stack().index.tolist()\n",
    "\n",
    "display(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57b48c-fe8e-426a-8f6b-3f2217a7f9ed",
   "metadata": {},
   "source": [
    "### Avec des variables numériques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ccb44-9eeb-4a77-b1fd-c91b6e26ebe5",
   "metadata": {},
   "source": [
    "Dans l’exemple précédent, les variables enregistraient des données catégorielles. Si maintenant nous prenons l’exemple d’une dizaine de textes avec des scores sur 20 dans cinq catégories :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a687d-42b0-41ab-992e-279f43365f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 texts with a score on 5 categories\n",
    "n_texts = 10\n",
    "categories = [\"Sciences\", \"Politique\", \"Littérature\", \"Journalisme\", \"Philosophie\"]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=np.random.randint(0, 21, size=(n_texts, len(categories))),\n",
    "    index=[f\"Text {i + 1}\" for i in range(0, n_texts)],\n",
    "    columns=categories\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c3e2d0-3e4e-43d5-af28-5f14d41307b3",
   "metadata": {},
   "source": [
    "Il n’est plus question ici de repérer les catégories où les textes ont obtenu des scores différents, aussi la première étape consiste à calculer une matrice de corrélation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a43442-2eb1-4196-94a4-9e188123cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "display(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd5f10-c543-4379-a05f-992823737c92",
   "metadata": {},
   "source": [
    "Cette matrice ressort des coefficients variant de -1 à 1 pour exprimer la corrélation entre chaque paire de variables. Pour la transformer en une matrice de dissimilarité, il suffit de calculer l’inverse de la corrélation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9655004-9bfe-4f8c-bdba-959dfe6596f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissimilarity_matrix = 1 / correlation_matrix\n",
    "\n",
    "display(dissimilarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff77d7-b270-47fd-8601-8623f1aca0cb",
   "metadata": {},
   "source": [
    "Une formule alternative consiste à calculer plutôt l’opposé de la corrélation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b34555-16fa-4b89-83ef-fffa013cfc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissimilarity_matrix = 1 - correlation_matrix\n",
    "\n",
    "display(dissimilarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07722506-b655-41b8-8e04-8c60ccc47d42",
   "metadata": {},
   "source": [
    "Puis à normaliser afin d’obtenir des scores dans l’intervalle $[0,1]$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3a0c6-b893-469f-aef0-d309fcd9e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dissimilarity_matrix / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d409b-8815-43c2-af0f-56542e4e08d4",
   "metadata": {},
   "source": [
    "De là, nous pouvons effectuer des prédictions sur les *clusters* formés entre les catégories. Peut-être la littérature et la philosophie sont-elles liées par leur coefficient de dissimilarité et, comme la philosophie et la politique sont elles-mêmes reliées, pourrions-nous en conclure que les trois disciplines forment un groupe.\n",
    "\n",
    "**Remarque :** les données sont générées aléatoirement aussi les groupes seront-ils toujours différents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d4f99-3233-4ca0-81d3-29504803770e",
   "metadata": {},
   "source": [
    "## Une matrice de distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec0db63-49fd-4466-a5e0-e3a09d7d38cf",
   "metadata": {},
   "source": [
    "Bien souvent, lorsque l’on calcule la dissimilarité entre des vecteurs, on calcule la distance euclidienne :\n",
    "\n",
    "$$\n",
    "d(\\mathbf{x}, \\mathbf{y}) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477ee91-61b2-4df5-8588-78ee1442dbf4",
   "metadata": {},
   "source": [
    "### Calcul de la distance euclidienne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab24a1-7e13-4c13-b646-5a9f934e60f3",
   "metadata": {},
   "source": [
    "La fonction peut s’interpréter en Python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8e720-6fd0-4ac9-927c-1ad2fd165722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(*, a:list, b:list) -> float:\n",
    "    \"\"\"Euclidean distance between two vectors.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    a -- first vector\n",
    "    b -- second vector\n",
    "    \"\"\"\n",
    "    # difference between indices\n",
    "    coords = [\n",
    "        (x - y) ** 2\n",
    "        for x, y in zip(a, b)\n",
    "    ]\n",
    "    # distance = square root of the sum of coords\n",
    "    return sum(coords) ** .5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9767a9-ed24-4f33-b6cc-0eb87e4b617a",
   "metadata": {},
   "source": [
    "Pour l’appliquer à notre jeu de données, on va d’abord générer une matrice de distances nulle avant de la remplir en se servant de la symétrie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7785b2e3-da44-4e0b-aef1-b8f21134a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a null matrix\n",
    "pairwise_distances = np.zeros((n_texts, n_texts))\n",
    "\n",
    "for i in range(n_texts):\n",
    "    for j in range(i, n_texts):  # start at 'i' to avoid calculating b-a pair if a-b already stored\n",
    "        dist = euclidean_distance(a=df.iloc[i].values.tolist(), b=df.iloc[j].values.tolist())\n",
    "        pairwise_distances[i, j] = dist\n",
    "        pairwise_distances[j, i] = dist  # matrix is symetric\n",
    "\n",
    "display(pairwise_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791b6c8-4cb5-4683-9f73-833cad08b442",
   "metadata": {},
   "source": [
    "### Calcul avec *Numpy*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de5d1b-5b53-44fd-babe-f3cbd69ddfbc",
   "metadata": {},
   "source": [
    "Calculer la distance euclidienne entre deux vecteurs *a* et *b* revient à calculer la norme du vecteur différence $a - b$.\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{v}\\| = \\sqrt{\\sum_{i=1}^{n} v_i^2}\n",
    "$$\n",
    "\n",
    "Or, la fonction `.linalg.norm()` de *Numpy* permet d’obtenir directement la norme d’un vecteur ; aussi pouvons-nous nous passer de la fonction `euclidean_distance()` définie plus haut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e5447-1ebf-47f3-8cae-d61705872f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a null matrix\n",
    "pairwise_distances = np.zeros((n_texts, n_texts))\n",
    "\n",
    "for i in range(n_texts):\n",
    "    # find vector a\n",
    "    vector_a = df.iloc[i].values\n",
    "    for j in range(i, n_texts):\n",
    "        # find vector b\n",
    "        vector_b = df.iloc[j].values\n",
    "        dist = np.linalg.norm(vector_a - vector_b)\n",
    "        pairwise_distances[i, j] = dist\n",
    "        pairwise_distances[j, i] = dist\n",
    "\n",
    "display(pairwise_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221450a-ee13-4496-878b-d4515e1c69f7",
   "metadata": {},
   "source": [
    "### Une bibliothèque scientifique spécialisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a173b-6cb4-4e06-ad14-e494b983a56b",
   "metadata": {},
   "source": [
    "La bilbiothèque *Scipy* fournit des méthodes spécialisées pour le calcul scientifique. Utilisons les fonctions `pdist` et `squareform` du module `spatial.distance` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d469d09-4d66-4448-b6c0-efb90895d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean matrix\n",
    "distances = pdist(df.values, metric='euclidean')\n",
    "\n",
    "# to a square matrix\n",
    "distance_matrix = squareform(distances)\n",
    "\n",
    "# to a dataframe\n",
    "distance_df = pd.DataFrame(distance_matrix, index=df.index, columns=df.index)\n",
    "\n",
    "display(distance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0410a6-1809-40c3-9b78-971e2420fa03",
   "metadata": {},
   "source": [
    "## Le regroupement hiérarchique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faabf20-b2fd-4195-8b0d-deb040eaee15",
   "metadata": {},
   "source": [
    "Jusqu’ici, les techniques de partitionnement proposées étaient plutôt simples et élémentaires : elles permettaient de dégager des appariements, tout au plus des regroupements de trois éléments. L’objectif à présent est de présenter une méthode plus systématique qui va, à chaque étape, effectuer des regroupements deux à deux jusqu’à ce qu’il ne reste plus qu’un seul groupe constitué de l’ensemble des autres.\n",
    "\n",
    "On peut matérialiser cette méthode grâce à un dendogramme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3af5df-925b-4e32-974b-f86476a64517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, euclidean distance\n",
    "Z = hierarchy.linkage(df, method='single')\n",
    "\n",
    "# plot dendrogram\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Distance')\n",
    "_ = hierarchy.dendrogram(\n",
    "    Z,\n",
    "    labels=df.index,\n",
    "    leaf_rotation=90,\n",
    "    leaf_font_size=10,\n",
    "    color_threshold=0.7 * max(Z[:, 2])\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c0187-9bc2-4325-8cb2-2ef40d4026cb",
   "metadata": {},
   "source": [
    "### Le clustering par liaison simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b44ff7-cb60-4194-b2e4-580e26c493e7",
   "metadata": {},
   "source": [
    "Une technique assez intuitive de regroupement repose sur l’idée que clusters sont reliés si deux de leurs composants sont plus proches l’un de l’autre que de n’importe quel autre composant d’un autre cluster. Pour illustrer cela, prenons quatre clusters *A*, *B*, *C* et *D* :\n",
    "\n",
    "|       | A      | B      | C   | D |\n",
    "|-------|--------|--------|----|----|\n",
    "| **A** | 0      | **12** | 13 | 34 |\n",
    "| **B** | **12** | 0      | 19 | 28 |\n",
    "| **C** | 13     | 19     | 0  | 15 |\n",
    "| **D** | 34     | 28     | 15 | 0  |\n",
    "\n",
    "Ici, les clusters *A* et *B* sont plus proches l’un de l’autre que de n’importe quel autre cluster, aussi pouvons-nous les regrouper. L’étape suivante va demander de réactualiser le tableau des distances où l’on remarque que les clusters $(A,B)$ et *C* sont désormais les plus proches :\n",
    "\n",
    "|            | (A,B)  | C      | D  |\n",
    "|------------|--------|--------|----|\n",
    "| **(A,B)**  | 0      | **13** | 28 |\n",
    "| **C**      | **13** | 0      | 15 |\n",
    "| **D**      | 28     | 15     | 0  |\n",
    "\n",
    "Après actualisation du tableau, nous obtenons :\n",
    "\n",
    "|               | ((A,B),C) | D  |\n",
    "|---------------|-----------|----|\n",
    "| **((A,B),C)** | 0         | 15 |\n",
    "| **D**         | 15        | 0  |\n",
    "\n",
    "À la fin, le cluster unique que nous avons formé est : $(((A,B),C), D)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4077f-3b8f-489e-b138-d3b956ab4d75",
   "metadata": {},
   "source": [
    "#### Décomposition étape par étape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0676bd06-4bdf-41aa-8028-d1dc46ec66b6",
   "metadata": {},
   "source": [
    "L’approche du clustering par liaison simple (ou *single-linkage clustering* en anglais) est dite agglomérative (ou *bottom-up*) dans le sens où elle forme des clusters élément par élément.\n",
    "\n",
    "À chaque étape, il est déjà possible de calculer le point de jonction entre les clusters, logiquement situé à équidistance entre leurs composants les plus proches. Par exemple, à la première étape, les clusters *A* et *B* sont à une distance de 12 l’un de l’autre. Si nous traçons une droite entre les deux et que nous devions en trouver le milieu, nous diviserions 12 par deux pour en déduire que le point de jonction entre les deux clusters se trouve à 6. À la seconde étape, le point de jonction entre les clusters *(A,B)* et *C* est situé à $13 \\div 2 = 6.5$.\n",
    "\n",
    "**Remarque :** on appellera plutôt ce point de jonction un nœud.\n",
    "\n",
    "Ensuite, la partie cruciale consiste à réactualiser la matrice des distances selon la fonction de liaison exprimée par la formule :\n",
    "\n",
    "$$\n",
    "D(X, Y) = \\min_{x \\in X, y \\in Y} d(x, y)\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- *X* et *Y* sont des clusters ;\n",
    "- *x* et *y* des composants de ces clusters.\n",
    "\n",
    "En reprenant notre exemple, et après avoir identifié que *A* et *B* étaient les clusters les plus proches et les avoir regroupés, nous devons déterminer lequel des deux était le plus proche de *C* et de *D* :\n",
    "\n",
    "- la distance *AC* est de 13, quand *BC* est de 19, aussi considère-t-on que le cluster $(A,B)$ se situe à une distance de 13 de *C* ;\n",
    "- $D((A,B),D) = \\min{(D(A,D), D(B,D))} = \\min{(34,28)} = 28$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db86cb9e-63f1-4ab3-92e6-b89b125e219f",
   "metadata": {},
   "source": [
    "#### Algorithme de résolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3a29f-81b0-4d4a-9466-9d9fe2c91562",
   "metadata": {},
   "source": [
    "Si l’on devait concevoir à la main un programme qui effectue un clustering par liaison simple, nous répertorerions les actions suivantes à mener :\n",
    "\n",
    "- calculer la distance entre les clusters ;\n",
    "- trouver les points les plus proches entre tous les clusters ;\n",
    "- déterminer entre tous les clusters qui sont les plus proches.\n",
    "\n",
    "Définissons les fonctions nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b72c2-1096-472e-97fc-4760c900cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_linkage(k:list, l:list, m) -> float:\n",
    "    \"\"\"Calculate the minimum distance between clusters,\n",
    "    according to the single-linkage method:\n",
    "    d(k, l) = min d(u, v)\n",
    "\n",
    "    Args:\n",
    "        k -- a cluster (collection of points)\n",
    "        l -- another cluster\n",
    "        m -- matrix\n",
    "\n",
    "    Usage example:\n",
    "        min_distance = single_linkage([0,3], [6,2,9], m)\n",
    "    \"\"\"\n",
    "    return min(np.linalg.norm(m[p_k] - m[p_l]) for p_k in k for p_l in l)\n",
    "\n",
    "def points_in_cluster(cluster):\n",
    "    \"\"\"A cluster is a collection of points.\"\"\"\n",
    "    return [int(point) for point in cluster.split(',')]\n",
    "\n",
    "def dist_between_clusters(n, clusters, m):\n",
    "    return [\n",
    "        0 if n == cluster else single_linkage(points_in_cluster(n), points_in_cluster(cluster), m)\n",
    "        for cluster in clusters.loc[n].index\n",
    "    ]\n",
    "\n",
    "def nearest_clusters(m):\n",
    "    \"\"\"Find the nearest clusters in a distance matrix.\"\"\"\n",
    "\n",
    "    # looking for the minimal distance\n",
    "    min_dist = m[m > 0].min().min()\n",
    "\n",
    "    # which clusters are concerned?\n",
    "    c_1, c_2 = np.where(m == min_dist)[0]\n",
    "\n",
    "    # and their names?\n",
    "    c_1_name = m.iloc[c_1].name\n",
    "    c_2_name = m.iloc[c_2].name\n",
    "\n",
    "    return (c_1_name, c_2_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ebf69-dd5c-45c0-8127-0846041c980b",
   "metadata": {},
   "source": [
    "**1e étape :** calculer une matrice des distances où au départ chaque point est un cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf32910-5626-488f-8235-f96ac1528740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a copy of the distance matrix\n",
    "cluster_df = pd.DataFrame(distance_df.values, index=[str(i) for i in range(len(distance_df))], columns=[str(i) for i in range(len(distance_df))])\n",
    "\n",
    "# how many clusters at the end?\n",
    "n = 2\n",
    "\n",
    "# how many steps in total?\n",
    "n_steps = len(cluster_df) - n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a504c-beff-460e-b517-4a7da878204d",
   "metadata": {},
   "source": [
    "**2e étape :** trouver les clusters les plus proches et les regrouper (à répéter autant de fois que nécessaire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822e37e-cc4e-48df-bdc4-58ecab085547",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_steps):\n",
    "\n",
    "    # find the nearest clusters\n",
    "    c_1, c_2 = nearest_clusters(cluster_df)\n",
    "    new_cluster = ','.join([c_1, c_2])\n",
    "\n",
    "    # new cluster in town\n",
    "    cluster_df.loc[new_cluster] = np.zeros(len(cluster_df))\n",
    "    cluster_df[new_cluster] = np.zeros(len(cluster_df))\n",
    "\n",
    "    # update distance matrix\n",
    "    cluster_df.loc[new_cluster] = dist_between_clusters(new_cluster, cluster_df, distance_df.values)\n",
    "    cluster_df[new_cluster] = dist_between_clusters(new_cluster, cluster_df, distance_df.values)\n",
    "\n",
    "    # delete merged clusters\n",
    "    cluster_df.drop([c_1, c_2], axis=0, inplace=True)\n",
    "    cluster_df.drop([c_1, c_2], axis=1, inplace=True)\n",
    "\n",
    "    # result\n",
    "    print(f\"Step {i + 1}: {','.join(str(int(x) + 1) for x in new_cluster.split(','))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d1ae57-43b0-466a-b116-426902e8b2b2",
   "metadata": {},
   "source": [
    "### Le clustering par liaison complète"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98805c04-38a2-460c-96f7-e77154fa2775",
   "metadata": {},
   "source": [
    "Autre technique de partitionnement hiérarchique, le clustering par liaison complète (ou *complete-linkage clustering* en anglais) ne va pas considérer, contrairement au clustering par liaison simple, que la distance des points les plus proches de deux clusters définisse la distance entre les clusters, mais que ce soit plutôt la distance des points les plus éloignés.\n",
    "\n",
    "La fonction de laison s’exprime désormais par l’expression mathématique :\n",
    "\n",
    "$$\n",
    "D(X, Y) = \\max_{x \\in X, y \\in Y} d(x, y)\n",
    "$$\n",
    "\n",
    "En reprenant l’exemple plus haut, à la 1e étape les clusters *A* et *B* sont toujours les plus proches :\n",
    "\n",
    "|       | A      | B      | C   | D |\n",
    "|-------|--------|--------|----|----|\n",
    "| **A** | 0      | **12** | 13 | 34 |\n",
    "| **B** | **12** | 0      | 19 | 28 |\n",
    "| **C** | 13     | 19     | 0  | 15 |\n",
    "| **D** | 34     | 28     | 15 | 0  |\n",
    "\n",
    "Après réactualisation du tableau des distances avec la fonction de laison complète, nous obtenons :\n",
    "\n",
    "|            | (A,B) | C      | D      |\n",
    "|------------|-------|--------|--------|\n",
    "| **(A,B)**  | 0     | 19     | 34     |\n",
    "| **C**      | 19    | 0      | **15** |\n",
    "| **D**      | 34    | **15** | 0      |\n",
    "\n",
    "Avec cette technique, le cluster $(A,B)$ s’est éloigné de *C* et de *D*, si bien que ces deux derniers sont désormais les plus proches l’un de l’autre :\n",
    "\n",
    "|               | (A,B) | (C,D) |\n",
    "|---------------|-------|-------|\n",
    "| **(A,B)**     | 0     | 34    |\n",
    "| **(C,D)**     | 34    | 0     |\n",
    "\n",
    "À la fin, le cluster unique que nous avons formé est : $((A,B), (C,D))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f46b2d-8469-4370-9a9d-9a2274584fed",
   "metadata": {},
   "source": [
    "#### Décomposition par étapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b456f-e11e-40d6-b1a0-a14013310b0d",
   "metadata": {},
   "source": [
    "À chaque étape, il convient de regrouper d’abord deux clusters en fonction de leur proximité puis de recalculer la distance qui les sépare des autres en prenant le point le plus éloigné.\n",
    "\n",
    "Ainsi, après avoir identifié dans notre exemple que *A* et *B* étaient les clusters les plus proches et les avoir regroupés, nous devons déterminer lequel des deux était le plus **éloigné** de *C* et de *D* :\n",
    "\n",
    "- la distance *AC* est de 13, quand *BC* est de 19, aussi considère-t-on que le cluster $(A,B)$ se situe à une distance de 19 de *C* ;\n",
    "- $D((A,B),D) = \\max{(D(A,D), D(B,D))} = \\max{(34,28)} = 34$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b800e41-480b-40ed-8399-b830d8a9516a",
   "metadata": {},
   "source": [
    "#### Algorithme de résolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b2c99-354f-479b-8f34-3e6e792c6993",
   "metadata": {},
   "source": [
    "L’algorithme est pour ainsi dire identique à celui du clustering par liaison simple. Nous avons juste besoin d’une fonction spécifique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad602b40-6c7f-45cf-bbb8-241d9bc6ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_linkage(k:list, l:list, m) -> float:\n",
    "    \"\"\"Calculate the maximum distance between clusters,\n",
    "    according to the complete-linkage method:\n",
    "    d(k, l) = max d(u, v)\n",
    "\n",
    "    Args:\n",
    "        k -- a cluster (collection of points)\n",
    "        l -- another cluster\n",
    "        m -- matrix\n",
    "\n",
    "    Usage example:\n",
    "        max_distance = complete_linkage([0,3], [6,2,9], m)\n",
    "    \"\"\"\n",
    "    return max(np.linalg.norm(m[p_k] - m[p_l]) for p_k in k for p_l in l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7bd8f7-172e-42aa-b816-2cb5ac4740fa",
   "metadata": {},
   "source": [
    "Et de redéfinir `dist_between_clusters()` en faisant appel à la fonction `complete_linkage()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce1cef-5b2d-48b3-913f-4ecac39c0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_between_clusters(n, clusters, m):\n",
    "    return [\n",
    "        0 if n == cluster else complete_linkage(points_in_cluster(n), points_in_cluster(cluster), m)\n",
    "        for cluster in clusters.loc[n].index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3419a707-6dd4-4c96-98c8-c661853cda16",
   "metadata": {},
   "source": [
    "Pour le reste, la procédure est similaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910e323-bcb2-42a6-ba8c-e5ee9c9ced41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a copy of the distance matrix\n",
    "cluster_df = pd.DataFrame(distance_df.values, index=[str(i) for i in range(len(distance_df))], columns=[str(i) for i in range(len(distance_df))])\n",
    "\n",
    "# how many clusters at the end?\n",
    "n = 3\n",
    "\n",
    "# how many steps in total?\n",
    "n_steps = len(cluster_df) - n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc976e13-f732-428f-baf0-03855edefbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_steps):\n",
    "\n",
    "    # find the nearest clusters\n",
    "    c_1, c_2 = nearest_clusters(cluster_df)\n",
    "    new_cluster = ','.join([c_1, c_2])\n",
    "\n",
    "    # new cluster in town\n",
    "    cluster_df.loc[new_cluster] = np.zeros(len(cluster_df))\n",
    "    cluster_df[new_cluster] = np.zeros(len(cluster_df))\n",
    "\n",
    "    # update distance matrix\n",
    "    cluster_df.loc[new_cluster] = dist_between_clusters(new_cluster, cluster_df, distance_df.values)\n",
    "    cluster_df[new_cluster] = dist_between_clusters(new_cluster, cluster_df, distance_df.values)\n",
    "\n",
    "    # delete merged clusters\n",
    "    cluster_df.drop([c_1, c_2], axis=0, inplace=True)\n",
    "    cluster_df.drop([c_1, c_2], axis=1, inplace=True)\n",
    "\n",
    "    # result\n",
    "    print(f\"Step {i + 1}: {','.join(str(int(x) + 1) for x in new_cluster.split(','))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
