{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d410f858-16c1-4925-8474-8fd68566c9be",
   "metadata": {},
   "source": [
    "# L’analyse discriminante linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c070b4e-2629-442f-a29b-d9af65595f84",
   "metadata": {},
   "source": [
    "Dans le chapitre précédent, nous avons abordé les techniques de regroupement d’observations dans des partitions (*clusters*) à des fins de classification. L’analyse discriminante linéaire (LDA pour *Linear Discriminant Analysis*) intervient en quelque sorte après, dans le sens où elle s’attache à repérer les structures qui ont autorisé l’attribution des classes (groupes).\n",
    "\n",
    "Avant d’opérer une LDA, il faut s’assurer de respecter plusieurs contraintes :\n",
    "\n",
    "- Le jeu de données est complet ;\n",
    "- toutes les variables indépendantes sont continues (c’est-à-dire normalisées) ;\n",
    "- les classes ont correctement été assignées.\n",
    "\n",
    "Par ailleurs, une LDA repose sur deux hypothèses fondamentales :\n",
    "\n",
    "- **La multinormalité :** les variables indépendantes sont normalement distribuées au sein des classes.\n",
    "- **L’homoscédasticité :** les matrices de covariance des classes sont identiques.\n",
    "\n",
    "Ajoutons à cela que la LDA cherche à maximiser la variance inter-classes en minimisant la variance intra-classe, aboutissant à une séparation linéaire entre les classes. De fait, si les données ne sont pas séparables linéairement, la LDA risque de ne pas bien fonctionner.\n",
    "\n",
    "De nombreuses contraintes, qui ne doivent malgré tout pas empêcher d’utiliser cette technique : la LDA peut s’effectuer sur des données multi-classes et ne demande pas d’énormes calculs contrairement à d’autres comme la régression logistique pour des résultats équivalents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e46410-26cc-4195-9e06-56f1cd87ce31",
   "metadata": {},
   "source": [
    "## Présentation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2800573a-5f43-458a-99d3-225cfb8962cf",
   "metadata": {},
   "source": [
    "Commençons par charger toutes les bibliothèques nécessaires pour ce projet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc765c-852e-46ae-b405-5da6310cf276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa182f0-8ec0-4b40-9c47-f479c1229b03",
   "metadata": {},
   "source": [
    "Prenons ensuite un jeu de données réduit issu d’une courte analyse de neuf fichiers appartenant au corpus *Brown*. L’objectif est de déterminer la meilleure manière d’analyser les données pour attribuer à coup sûr la bonne catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4624b-1642-42f2-8382-d9744053b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Tokens': [2374, 2370, 2428, 2213, 2334, 2332, 2200, 2234, 2244],\n",
    "    'Types': [745, 672, 737, 743, 735, 833, 956, 916, 908],\n",
    "    'TTR': [0.313816, 0.283544, 0.303542, 0.335743, 0.31491, 0.357204, 0.434545, 0.410027, 0.404635],\n",
    "    'Sents': [150, 147, 189, 84, 67, 84, 103, 95, 96],\n",
    "    'Average sentence length': [15.8267, 16.1224, 12.8466, 26.3452, 34.8358, 27.7619, 21.3592, 23.5158, 23.375],\n",
    "    '1-letter words': [416, 398, 361, 227, 262, 286, 213, 210, 265],\n",
    "    '2-letter words': [430, 432, 424, 451, 559, 384, 334, 372, 371],\n",
    "    '>15-letter words': [1, 2, 0, 1, 9, 3, 3, 6, 2],\n",
    "    'Average word length': [3.68618, 3.66624, 3.63715, 4.26661, 4.39674, 4.58533, 4.75455, 4.61549, 4.29055],\n",
    "    'Category': ['mystery', 'mystery', 'mystery', 'religion', 'religion', 'religion', 'editorial', 'editorial', 'editorial']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index=['cl01', 'cl02', 'cl03', 'cd01', 'cd02', 'cd03', 'cb01', 'cb02', 'cb03'])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58dcec2-3e27-47d1-9eed-e35a26d61f2f",
   "metadata": {},
   "source": [
    "## Étape 1 : choisir les variables prédictives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1cd19-1db9-4332-b414-eff13eca34d0",
   "metadata": {},
   "source": [
    "La première étape consiste à séparer les variables prédictives (celles qui nous aideront dans nos prédictions) de la variable dépendante (celle que l’on cherche à prédire). Nous identifions par ailleurs des variables redondantes : l’indice TTR étant un ratio entre les mots-formes uniques et le nombre de tokens, on peut retirer sans perte de notre modèle les variables *Tokens* et *Types*. Même traitement pour la variable *Sents* qui, à partir du moment où nous connaissons le nombre de tokens et la longueur moyenne d’une phrase, peut-être reconstituée.\n",
    "\n",
    "Nos matrices deviennent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee5ca0-180f-49e3-98e4-fe63a7193b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictive variables\n",
    "X = df.drop(columns=['Tokens', 'Types', 'Sents', 'Category']).values\n",
    "\n",
    "# target\n",
    "y = df['Category'].values\n",
    "\n",
    "# unique classes\n",
    "classes = np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5261984-9588-43f9-8061-20b72ad00cbe",
   "metadata": {},
   "source": [
    "## Étape 2 : normaliser les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b365b-ca10-4e82-ba91-3fd5e36f0d5f",
   "metadata": {},
   "source": [
    "On ne le répétera jamais assez, il est généralement recommandé de normaliser sa matrice de données : d’une part certaines variables sont sur des échelles très différentes, ce qui peut influencer l’analyse ; d’autre part les algorithmes sont plus robustes en travaillant avec des variables continues.\n",
    "\n",
    "Pour *X*, on obtient :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94345e-7234-4efe-87b2-30e4e5e7e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97a98c-7098-44bc-a09a-965e597b330a",
   "metadata": {},
   "source": [
    "## Étape 3 : calculer les moyennes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6900579-7815-489a-a34e-849bc4c3cbb4",
   "metadata": {},
   "source": [
    "Afin de déterminer les variances inter-classes et intra-classes, il est nécessaire au préalable de calculer les moyennes globales et à l’intérieur des classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915a0a3-2b09-4c8b-a5c1-1e80dea35f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = X_scaled.mean(axis=0)\n",
    "means_per_class = {cls: X_scaled[y == cls].mean(axis=0) for cls in classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c292b0-c928-4519-8740-de84c4a32c61",
   "metadata": {},
   "source": [
    "## Étape 4 : établir les matrices de dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d8e01-6be0-4f0c-a975-dbc0d610bc3d",
   "metadata": {},
   "source": [
    "À cette étape, notre objectif est d’une part de révéler la manière dont les données varient à l’intérieur de leur classe et d’autre part comment les moyennes varient entre elles. Deux matrices seront calculées :\n",
    "\n",
    "- la matrice de dispersion intra-classe ($S_W$), qui analyse la variance/covariance des données à l’intérieur de leur classe ;\n",
    "- la matrice de dispersion inter-classe ($S_B$), qui mesure la variance entre les moyennes des classes.\n",
    "\n",
    "Avant tout, initialisons des matrices carrées nulles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4136529-1d77-41a0-91bc-c8c5a63ba6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "S_W = np.zeros((X_scaled.shape[1], X_scaled.shape[1]))\n",
    "S_B = np.zeros((X_scaled.shape[1], X_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b371e6-be57-4760-b212-95c219b43dd5",
   "metadata": {},
   "source": [
    "### La matrice de dispersion intra-classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5fab3-85df-4a7f-a132-9027b73ace09",
   "metadata": {},
   "source": [
    "Pour mesurer la variance à l’intérieur de chaque classe, nous devons nous intéresser à la dispersion des données par rapport à la moyenne dans chaque classe. La formule établit que :\n",
    "\n",
    "$$\n",
    "S_W = \\sum_{k=1}^{K} \\sum_{i \\in C_k} (x_i - \\mu_k)(x_i - \\mu_k)^T\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- $K$ est le nombre de classes ;\n",
    "- $C_k$ représente les données dans la classe $k$ ;\n",
    "- $x_i$ est un vecteur de caractéristiques pour l’exemple $i$ dans la classe $k$ ;\n",
    "- $\\mu_k$ est la moyenne des caractéristiques dans la classe $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78aa29d-b0aa-47a5-87c6-3b9547ecff4d",
   "metadata": {},
   "source": [
    "### La matrice de dispersion inter-classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a74eeb-d79f-4af5-9007-aa211124aa46",
   "metadata": {},
   "source": [
    "Cette matrice se construit en analysant les moyennes des classes varient entre elles à partir de l’expression suivante :\n",
    "\n",
    "$$\n",
    "S_B = \\sum_{k=1}^{K} N_k (\\mu_k - \\mu)(\\mu_k - \\mu)^T\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- $N_k$ est le nombre d'éléments dans la classe $k$ ;\n",
    "- $\\mu_k$ est la moyenne des caractéristiques de la classe $k$ ;\n",
    "- $\\mu$ est la moyenne globale de toutes les classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c101e468-e079-4523-af7d-7ed00175ad20",
   "metadata": {},
   "source": [
    "### Résolution des calculs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124ac97-e119-48ac-af90-2d86ae589dd2",
   "metadata": {},
   "source": [
    "Les opérations se réalisent en une passe avec *Numpy* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55675d-daff-41e0-972c-90bdbf312add",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in classes:\n",
    "    # matrix for a class\n",
    "    X_i = X_scaled[y == i]\n",
    "    mu_k = means_per_class[i]\n",
    "    \n",
    "    # within-class scatter\n",
    "    S_W += np.dot((X_i - mu_k).T, (X_i - mu_k))\n",
    "    \n",
    "    # between-class scatter\n",
    "    n_k = X_i.shape[0]\n",
    "    S_B += n_k * np.outer((mu_k - mu), (mu_k - mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674a375-cf6e-4596-8147-1bd354c5df30",
   "metadata": {},
   "source": [
    "**Explications :**\n",
    "\n",
    "- Pour chaque classe, nous conservons une matrice $3 \\times 6$ des trois textes décrits par les six variables ainsi qu’un vecteur des six moyennes ;\n",
    "- $S_W$ étant définie dans l’espace des dimensions, nous souhaitons in fine une matrice $6 \\times 6$ et non une matrice $3 \\times 3$ ;\n",
    "- pour $S_W$, le produit matriciel $(X_i − \\mu_k)^T \\cdot (X_i − \\mu_k)$ équivaut à la somme des produits extérieurs $(x_i - \\mu_k)(x_i - \\mu_k)^T$ pour tous les $i \\in C_k $ ;\n",
    "- le produit extérieur des deux vecteurs $\\mu_k \\in \\mathbb{R}^6$ et $\\mu \\in \\mathbb{R}^6$ donne une matrice $6 \\times 6$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d580d49-e8f4-45a3-9c55-584a08c7377c",
   "metadata": {},
   "source": [
    "## Étape 5 : maximiser la séparation entre les classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b578c5a-afd2-4197-9004-b0d224a68ea6",
   "metadata": {},
   "source": [
    "Si notre objectif était simplement de minimiser la variance intra-classe, $S_W$ seule suffirait à l’analyse. Cependant, dans la LDA, l’objectif est double : rechercher aussi les directions discriminantes en projetant les données sur un sous-espace où la séparation des classes est maximisée. Mathématiquement, cela revient à calculer :\n",
    "\n",
    "$$\n",
    "S_W^{-1}S_B\n",
    "$$\n",
    "\n",
    "En prenant l’inverse de $S_W$, nous réduisons l’impact de la dispersion intra-classe sur la séparation entre les classes. Plus précisément, cela permet de mettre en évidence les directions de l’espace vectoriel où les classes sont le mieux séparées, tout en tenant compte de la variance intra-classe par la diminution de l’influence des directions où les classes se chevauchent le plus.\n",
    "\n",
    "Avec *Numpy*, on réalise l’opération simplement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a039cd-a39b-46f6-bc59-bbb42f908291",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_W_inv = np.linalg.inv(S_W)\n",
    "S_W_inv_S_B = np.dot(S_W_inv, S_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb3676-22a7-4641-8814-d12a0fdcc950",
   "metadata": {},
   "source": [
    "## Étape 6 : décomposer la matrice en éléments propres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d610d-0d6e-4d0c-8067-6d66e28a5bf9",
   "metadata": {},
   "source": [
    "Une fois la matrice $S_W^{-1}S_B$ obtenue, il reste à la décomposer en éléments propres afin de révéler :\n",
    "- Les **valeurs propres** (*eigenvalues*), qui quantifient la force de chaque direction discriminante.\n",
    "- Les **vecteurs propres** (*eigenvectors*), qui représentent les directions dans lesquelles la séparation des classes est maximisée.\n",
    "\n",
    "Pour rappel, la décomposition en éléments revient à exprimer une matrice carrée comme le résultat de l’équation :\n",
    "\n",
    "$$\n",
    "A = PDP^{-1}\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- $P$ est la matrice des vecteurs propres ;\n",
    "- $D$ la diagonale des valeurs propres ;\n",
    "- $P^{-1}$ l’inverse de $P$ si $A$ est diagonalisable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78695c-671b-439e-ad52-29969169fd74",
   "metadata": {},
   "source": [
    "### Calculer les valeurs propres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca1f95-da76-4f62-b0fd-b269668de1e8",
   "metadata": {},
   "source": [
    "Cela revient à extraire les racines du polynôme caractéristique de la matrice :\n",
    "\n",
    "$$\n",
    "P_M(x) = \\det[M - x.I_n]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed5cc56-c6a6-4a07-afb5-3f991b82f112",
   "metadata": {},
   "source": [
    "### Calculer les vecteurs propres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fdd373-1cbe-4918-b161-f4c8f9f14d0f",
   "metadata": {},
   "source": [
    "Les vecteurs propres sont les vecteurs associés aux valeurs propres d’une matrice. Elles répondent au système d’équation ci-dessous où $I_n$ est la matrice identité et $\\vec{X}$ un vecteur des racines du polynôme caractéristique :\n",
    "\n",
    "$$\n",
    "(M − \\lambda I_n)\\vec{X} = \\vec{0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35c72b-3ae2-41be-aea7-ad2e37e08c3b",
   "metadata": {},
   "source": [
    "### Projeter les données sur un sous-espace vectoriel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f2555-b26b-424f-bb30-8c074cdce60d",
   "metadata": {},
   "source": [
    "La méthode `.linalg.eig()` de *Numpy* effectue les calculs en une ligne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6c03c-7b51-4968-9c71-49be224e219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(S_W_inv_S_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3ed53-1d86-4285-9a5d-578fb7e77d02",
   "metadata": {},
   "source": [
    "Il reste maintenant à sélectionner les vecteurs propres pour les valeurs propres les plus fortes. Pour cela, nous ordonnons d’abord les valeurs propres par ordre décroissant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f8ea7-2c18-4dac-9879-ffbf643d9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices to sort the array?\n",
    "idx = eigenvalues.argsort()[::-1]\n",
    "\n",
    "# sorting & swiping out the imaginary part of the number\n",
    "eigenvalues = np.real(eigenvalues[idx])\n",
    "eigenvectors = np.real(eigenvectors[:, idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac0257-5a60-4b92-a90d-c3f37a8ede6c",
   "metadata": {},
   "source": [
    "Ensuite, nous décidons de la dimensionnalité du sous-espace dans lequel nous souhaitons projeter les données, avec la contrainte qu’il peut, au maximum, avoir autant de dimensions que de classes $-1$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c91830-1a83-4643-b6b7-fd9637a4ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dimensions (max here: 2)\n",
    "k = 2\n",
    "\n",
    "# select the k eigenvectors\n",
    "components = eigenvectors[:, :k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97eaa67-a652-4ab8-aa5d-4cc81cf8db14",
   "metadata": {},
   "source": [
    "Finalement, nous projetons les données sur le sous-espace :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c22e50-50fa-4df4-a87b-f5b312bd6757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_projected = np.dot(X_scaled, components)\n",
    "\n",
    "# into a dataframe\n",
    "df_projected = pd.DataFrame(X_projected, index=df.index, columns=['Component 1', 'Component 2'])\n",
    "df_projected['Class'] = y\n",
    "\n",
    "display(df_projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f58c58-dba7-4d80-80b9-15196a16fc47",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b92094-80b6-408f-806f-663703cba6fa",
   "metadata": {},
   "source": [
    "Mettons que nous obtenons une nouvelle donnée pour laquelle nous souhaitons deviner la classe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3f4c2-9309-410b-bbd8-26e6aa3c1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a new text\n",
    "new_data = np.array([0.410961, 17.4314, 207, 498, 4, 3.72824]).reshape(1, -1)\n",
    "\n",
    "# standardization\n",
    "new_data_scaled = (new_data - new_data.mean()) / new_data.std()\n",
    "\n",
    "# projection\n",
    "new_data_projected = np.dot(new_data_scaled, components)\n",
    "\n",
    "# into a dataframe\n",
    "df_new = pd.DataFrame(new_data_projected, columns=['Component 1', 'Component 2'])\n",
    "df_new['Class'] = 'Unknown'\n",
    "\n",
    "# concatenation\n",
    "df_projected = pd.concat([df_projected, df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b558b95-5221-4566-aba8-6155b648c963",
   "metadata": {},
   "source": [
    "Preuve que la LDA a bien fonctionné, nous visualisons dans un nuage de points des partitions distinctes qui nous incitent à attribuer la classe *mystery* au nouveau texte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a835e0c-3398-4bcc-8249-67206ca1f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_projected,\n",
    "    x='Component 1',\n",
    "    y='Component 2',\n",
    "    hue='Class',\n",
    "    palette='Set2',\n",
    "    style='Class',\n",
    "    s=100,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "plt.title('Linear Discriminant Analysis (LDA)', fontsize=16)\n",
    "plt.xlabel('Component 1', fontsize=12)\n",
    "plt.ylabel('Component 2', fontsize=12)\n",
    "plt.legend(title='Class', title_fontsize='13', fontsize='11', loc='best')\n",
    "\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-1, 1)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97548b6-fae1-466a-a6c6-fb9fcc6559a4",
   "metadata": {},
   "source": [
    "## Établir un modèle discriminant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de7ecf-797d-4f37-9ee7-c38d9f8acaf0",
   "metadata": {},
   "source": [
    "Si elle s’interprète facilement, la preuve graphique n’est pas suffisante pour parler de modèle de classification. Une fois les données projetées sur un sous-espace de $k-1$ classes, nous pouvons construire un modèle basé sur les fonctions discriminantes de la LDA :\n",
    "\n",
    "$$\n",
    "g_k(x) = W_k \\cdot x + b_k\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- $W_k$ figure les coefficients (ou poids) ;\n",
    "- $b_k$ le biais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c99ca-0462-47ea-8885-9e388da21106",
   "metadata": {},
   "source": [
    "### Calculer les coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e4160-c6ff-465a-a0e3-4a2d3481b428",
   "metadata": {},
   "source": [
    "La matrice des coefficients se calcule comme :\n",
    "\n",
    "$$\n",
    "W_k = S_W^{−1} \\cdot (\\mu_k − \\mu)\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- $\\mu_k$ la moyenne de la classe $k$ ;\n",
    "- $\\mu$ la moyenne globale.\n",
    "\n",
    "Nous avons besoin de connaître en premier lieu les moyennes globale et de chaque classe dans l’espace projeté :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae80803-46b5-4d84-8da7-d8ddf6861b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall mean in the projected space\n",
    "mean_overall = np.mean(X_projected, axis=0)\n",
    "\n",
    "# mean of each class in the projected space\n",
    "means_per_class = [np.mean(X_projected[y == c], axis=0) for c in classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0e75d-2410-4f26-b3ee-b8b43bca5725",
   "metadata": {},
   "source": [
    "Ensuite, nous recalculons l’inverse de la matrice de dispersion intra-classe dans l’espace projeté. Dans ce contexte, $S_W$ se comprend comme la matrice de covariance des dimensions réduites obtenues après projection sur les vecteurs propres. Comme `X_projected` est une matrice contenant en lignes les observations et en colonnes les dimensions, il nous suffit de la transposer pour obtenir la covariance des dimensions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3e3cb-7504-4e5d-8147-6b6a21d1953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_W_projected = np.cov(X_projected.T)\n",
    "S_W_inv = np.linalg.inv(S_W_projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd2264-ee55-4538-a759-ed3bf51d1f56",
   "metadata": {},
   "source": [
    "### Calculer le biais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445b15f-1dd8-4e02-a470-ffdbee4d97d4",
   "metadata": {},
   "source": [
    "Le biais est calculé par :\n",
    "\n",
    "$$\n",
    "b_k = -\\frac{1}{2} \\mu_k^T \\cdot S_W^{−1} \\cdot \\mu_k + \\log⁡(\\pi_k)\n",
    "$$\n",
    "\n",
    "Où $\\pi_k$ est le *prior* (probabilité a priori) de la classe $k$. L’existence de ce *prior* se justifie par la possibilité de déséquilibre de représentation d’une classe dans les données d’apprentissage. Pour éviter ce risque, le modèle prend en compte les connaissances a priori. De manière naïve, en présence de trois classes nous estimons le *prior* à 0.33 pour chacune.\n",
    "\n",
    "Dans la pratique, il faut considérer ce mécanisme comme une possibilité de représenter les connaissances a priori : si nous sommes certain·es qu’une classe se rencontre davantage dans la nature, il nous faudra bouger le curseur en conséquence. Et si en revanche les données sont parfaitement équilibrées, comme dans notre exemple où nous avons trois représentants de chaque classe, les *priors* n’auront aucun impact et pourraient être ignorées. Nous tenons toutefois à les conserver :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f30461-6e26-42db-8462-c99d01e7dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = [np.sum(y == c) / len(y) for c in classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1c75d1-d8c0-4990-8d23-fbf15d4dfd6f",
   "metadata": {},
   "source": [
    "### Construire le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb8f058-8a72-4cd7-be84-9fd1e370bb2f",
   "metadata": {},
   "source": [
    "Tous les éléments étant en place, nous pouvons construire le modèle en reprenant la formule énoncée plus haut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4376f-a2ad-439c-864f-804fdd53ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = []\n",
    "for k, class_mean in enumerate(means_per_class):\n",
    "    W_k = np.dot(S_W_inv, class_mean - mean_overall)\n",
    "    b_k = -0.5 * np.dot(class_mean, np.dot(S_W_inv, class_mean)) + np.log(priors[k])\n",
    "    coefficients.append((W_k, b_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4db97-f31e-4546-bdbc-e0dbd4cccfc4",
   "metadata": {},
   "source": [
    "### Effectuer des prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bf567d-7fae-458a-95f0-a2425e419973",
   "metadata": {},
   "source": [
    "Il est temps d’utiliser le modèle pour prédire la classe de notre nouvelle observation, selon l'expression :\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\arg \\max_k g_k(x)\n",
    "$$\n",
    "\n",
    "La formule se comprend facilement : nous appliquons la fonction discriminante du modèle ajusté à chaque classe et choisissons la classe correspondant à l’argument qui maximise la fonction discriminante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae672c4-202a-4656-bafc-d93e3f4687e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    "    np.dot(new_data_projected, W_k) + b_k\n",
    "    for W_k, b_k in coefficients\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Score : {np.max(scores):.4f}\",\n",
    "    f\"Catégorie : {classes[np.argmax(scores)]}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d81ab-d48f-4dfd-8516-c367a7431350",
   "metadata": {},
   "source": [
    "Cerise sur le gâteau, il est possible de ressortir la probabilité associée à chaque classe grâce à la fonction de densité a posteriori :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6c463-7c52-4479-a2f7-19c8464741a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# according to Bayes theorem\n",
    "exps = np.exp(scores - np.max(scores))\n",
    "probabilities = exps / np.sum(exps)\n",
    "\n",
    "for class_name, p in zip(classes, probabilities):\n",
    "    print(f'{class_name} : {p[0]:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2515bbe1-8b09-486a-84e7-4073403ff3c5",
   "metadata": {},
   "source": [
    "## Évaluer la performance du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e1ecb-365f-435a-b718-79af373b5c77",
   "metadata": {},
   "source": [
    "Dans une tâche de classification, on évalue généralement la performance du modèle avec une matrice de confusion et ses métriques dérivées : la **précision**, le **rappel**, et le **score F1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d63fe9-b3e4-4ec3-a7e4-f6b71b9467ab",
   "metadata": {},
   "source": [
    "### Des données de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0438dc-8df6-4b3f-a61e-098b17516ba8",
   "metadata": {},
   "source": [
    "Comme nous avons entraîné notre modèle sur des textes issus du corpus *Brown*, prenons d’autres textes pour lesquels nous connaissons la bonne catégorie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7efa6-32af-408e-ad36-5b4c97d98a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/brown.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# first 5 texts\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918615e-1de2-4341-ab82-f221b9c4affb",
   "metadata": {},
   "source": [
    "### Préparer les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c43a639-238c-404b-b886-b43e76235f95",
   "metadata": {},
   "source": [
    "Il convient désormais de préparer les données de test de la même manière que celles qui ont servi lors de la phase d‘apprentissage :\n",
    "\n",
    "1. Sélectionner les variables ;\n",
    "2. Normaliser ;\n",
    "3. Projeter dans le sous-espace vectoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce8819-190b-43e9-973d-5e8c0a171dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df.drop(columns=['Category']).values\n",
    "X_test_scaled = (X_test - X_test.mean()) / X_test.std()\n",
    "X_test_projected = np.dot(X_test_scaled, components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8935212-6582-4fc4-a49c-80e1e199814e",
   "metadata": {},
   "source": [
    "### Appliquer le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca242854-d087-4b9d-8196-28215adac0e8",
   "metadata": {},
   "source": [
    "Il reste à appliquer le modèle pour chaque nouvelle observation, ressortir les scores et prédire leur classe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64707721-a739-4213-a4dc-70d6bfe73df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    "    [\n",
    "        np.dot(data, W_k) + b_k\n",
    "        for W_k, b_k in coefficients\n",
    "    ]\n",
    "    for data in X_test_projected\n",
    "]\n",
    "y_pred = classes[np.argmax(scores, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f768e-476b-43d9-9b05-72cad850ec4e",
   "metadata": {},
   "source": [
    "### Métriques d’évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552257d-7f82-430f-ad12-3d800e62f5f8",
   "metadata": {},
   "source": [
    "#### Déterminer la précision globale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a09e9-b196-440e-9df4-0610932a4108",
   "metadata": {},
   "source": [
    "Pour connaître la précision globale de notre modèle, nous allons calculer le taux de bonnes réponses :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b1222-0fbf-49bc-a2dc-ecf6303b5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df.Category\n",
    "global_accuracy = sum(y_pred == y_test) / len(y_pred)\n",
    "\n",
    "print(f'Précision globale : {global_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a85fd5-9268-4c5d-8c9e-70ea45759735",
   "metadata": {},
   "source": [
    "#### Établir la matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a59894-b162-4a63-8bc1-5ccfe650b3d9",
   "metadata": {},
   "source": [
    "La précision globale n’est pas très rassurante. Regardons en détail avec la matrice de confusion. Utilisons pour cela la bibliothèque *Scikit-Learn* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7b697-3943-4299-97e9-a4269fc7a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4dbc2-f867-415f-a7ba-9dc7a9ce069b",
   "metadata": {},
   "source": [
    "Chaque ligne de la matrice correspond à une classe réelle et chaque colonne à une classe prédite. Visuellement, il est plus simple d’analyser la matrice de confusion avec une carte de chaleur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6146b-52cb-4ec8-a46a-8957d910843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cfm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=classes,\n",
    "    yticklabels=classes\n",
    ")\n",
    "\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa0e26-e24b-41c6-ad27-a04a6cc8f9f2",
   "metadata": {},
   "source": [
    "Les résultats sont édifiants : notre modèle ne prédit qu’une classe pour tous les textes, ce qui explique sa lamentable performance globale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65639ccf-8671-4d92-8697-9ca9a77ff867",
   "metadata": {},
   "source": [
    "#### Les mesures dérivées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6ce2e7-27e8-40cd-8d36-8f78d6f1152d",
   "metadata": {},
   "source": [
    "Dans un cas de classification binaire, on a coutume de calculer des métriques basées sur quatre cas :\n",
    "\n",
    "- Les **vrais positifs** (*true positive* ou TP) : le nombre de fois où le modèle a attribué correctement la classe positive ;\n",
    "- les **faux positifs** (*false positive* ou FP) : le nombre de fois où le modèle a faussement attribué la classe positive à un exemple qui appartient en réalité à la classe négative ;\n",
    "- les **vrais négatifs** (*true negative* ou TN) : le nombre de fois où le modèle a attribué correctement la classe négative ;\n",
    "- les **faux négatifs** (*false negative* ou FN) : le nombre de fois où le modèle a faussement attribué la classe négative à un exemple qui appartient en réalité à la classe positive.\n",
    "\n",
    "De là, nous pouvons calculer des métriques importantes telles que la précision, le rappel, la spécificité, et le score F1.\n",
    "\n",
    "La **précision** (*precision*) s’intéresse à l’exactitude des prédictions positives et se résout avec la formule :\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "Le **rappel** (*recall*), ou sensibilité, détermine le taux de classes positives que le modèle a correctement étiquetées selon la formule :\n",
    "\n",
    "$$\n",
    "\\text{recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Le **taux de vrais négatifs** (*true negative rate*), ou score de spécificité, mesure la capacité du modèle à identifier correctement les échantillons négatifs grâce au rapport :\n",
    "\n",
    "$$\n",
    "\\text{TNR} = \\frac{TN}{TN + FP}\n",
    "$$\n",
    "\n",
    "Le **score F1** établit quant à lui la moyenne harmonique entre la précision et le rappel :\n",
    "\n",
    "$$\n",
    "\\text{F1} = 2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}\n",
    "$$\n",
    "\n",
    "Dans notre exemple, nous sommes dans le cas d’une classification multi-classes où le modèle doit choisir parmi plusieurs laquelle est la plus adaptée. Pour cette raison, la classe positive est la classe qu’il faudrait attribuer et la classe négative est constituée de toutes les autres.\n",
    "\n",
    "Intéressons-nous uniquement aux résultats pour la classe positive *mystery* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04818c73-ab3f-4fa1-b5f9-041b553758c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, TN, FN = 21, 38, 0, 0\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "TNR = TN / (TN + FP)\n",
    "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "print(\n",
    "    f\"Précision : {precision:.4f}\",\n",
    "    f\"Rappel : {recall:.4f}\",\n",
    "    f\"TNR : {TNR:.4f}\",\n",
    "    f\"Score F1 : {f1_score:.4f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2462e0-140f-47c5-9d0f-1c0299d25bef",
   "metadata": {},
   "source": [
    "#### Interprétation des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc49686-9bab-4322-ab12-001f41c45dc1",
   "metadata": {},
   "source": [
    "Avec un rappel de 1, notre modèle identifie clairement tous les textes de la catégorie *mystery* dans le jeu de données de test, sans ne jamais se tromper. Mais ne nous réjouissons pas hâtivement : nous parviendrions au même résultat si on attribuait à tous les textes la même étiquette.\n",
    "\n",
    "C’est ce que nous enseigne le taux de vrais négatifs : le modèle n’est jamais parvenu à identifier une classe autre que *mystery*…\n",
    "\n",
    "Par ailleurs, souvenons-nous que la précision est loin d’être folle : seulement 36 % de bonnes étiquettes attribuées. Aussi, le score F1 nous conforte dans ce triste constat : le modèle n’équilibre pas la précision et le rappel de manière optimale.\n",
    "\n",
    "La raison de cet échec ne viendrait-elle pas de la faible quantité de données sur lesquelles nous avons entraîné notre modèle ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
